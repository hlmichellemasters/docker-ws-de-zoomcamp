{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23dfcc4-3eba-4dde-b481-7b4154076b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "639acd17-4cdc-4c4c-ae5b-9b2c4fc5d66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>cbd_congestion_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 00:34:48</td>\n",
       "      <td>2025-11-01 00:41:39</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 00:18:52</td>\n",
       "      <td>2025-11-01 00:24:27</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 01:03:14</td>\n",
       "      <td>2025-11-01 01:15:24</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>13.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 00:10:57</td>\n",
       "      <td>2025-11-01 00:24:53</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.44</td>\n",
       "      <td>24.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-01 00:03:48</td>\n",
       "      <td>2025-11-01 00:19:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2025-11-01 00:34:48   2025-11-01 00:41:39                  N   \n",
       "1         2  2025-11-01 00:18:52   2025-11-01 00:24:27                  N   \n",
       "2         2  2025-11-01 01:03:14   2025-11-01 01:15:24                  N   \n",
       "3         2  2025-11-01 00:10:57   2025-11-01 00:24:53                  N   \n",
       "4         1  2025-11-01 00:03:48   2025-11-01 00:19:38                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            74            42              1.0           0.74   \n",
       "1         1.0            74            42              2.0           0.95   \n",
       "2         1.0            83           160              1.0           2.19   \n",
       "3         1.0           166           127              1.0           5.44   \n",
       "4         1.0           166           262              1.0           3.20   \n",
       "\n",
       "   fare_amount  ...  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0          7.2  ...      0.5        1.94           0.0        NaN   \n",
       "1          7.2  ...      0.5        0.00           0.0        NaN   \n",
       "2         13.5  ...      0.5        5.00           0.0        NaN   \n",
       "3         24.7  ...      0.5        0.50           0.0        NaN   \n",
       "4         18.4  ...      1.5        1.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    1.0         11.64           1.0        1.0   \n",
       "1                    1.0          9.70           2.0        1.0   \n",
       "2                    1.0         21.00           1.0        1.0   \n",
       "3                    1.0         27.70           1.0        1.0   \n",
       "4                    1.0         24.65           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  cbd_congestion_fee  \n",
       "0                  0.00                 0.0  \n",
       "1                  0.00                 0.0  \n",
       "2                  0.00                 0.0  \n",
       "3                  0.00                 0.0  \n",
       "4                  2.75                 0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'https://d37ci6vzurychx.cloudfront.net/trip-data/'\n",
    "\n",
    "df = pd.read_parquet(prefix + 'green_tripdata_2025-11.parquet')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098a4682-3d5f-4938-b861-7c4fe7b8238f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int32\n",
       "lpep_pickup_datetime     datetime64[us]\n",
       "lpep_dropoff_datetime    datetime64[us]\n",
       "store_and_fwd_flag                  str\n",
       "RatecodeID                      float64\n",
       "PULocationID                      int32\n",
       "DOLocationID                      int32\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "ehail_fee                       float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "payment_type                    float64\n",
       "trip_type                       float64\n",
       "congestion_surcharge            float64\n",
       "cbd_congestion_fee              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214dcbb4-56d7-49a2-b51c-de1ba6af03c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46912, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6230bb9f-5128-476a-a5bf-a08dcad1331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforcing datatypes (such as ratecodeID, which came in as a float)\n",
    "dtype_map = {\n",
    "    \"VendorID\": \"Int64\",\n",
    "    \"passenger_count\": \"Int64\",\n",
    "    \"RatecodeID\": \"Int64\",\n",
    "    \"PULocationID\": \"Int64\",\n",
    "    \"DOLocationID\": \"Int64\",\n",
    "    \"payment_type\": \"Int64\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"extra\": \"float64\",\n",
    "    \"mta_tax\": \"float64\",\n",
    "    \"tip_amount\": \"float64\",\n",
    "    \"tolls_amount\": \"float64\",\n",
    "    \"improvement_surcharge\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"congestion_surcharge\": \"float64\",\n",
    "    \"cbd_congestion_fee\": \"float64\"\n",
    "}\n",
    "\n",
    "df = df.astype(dtype_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6694c35e-bc96-498b-a7f5-d0f34f2da782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          Int64\n",
       "lpep_pickup_datetime     datetime64[us]\n",
       "lpep_dropoff_datetime    datetime64[us]\n",
       "store_and_fwd_flag               string\n",
       "RatecodeID                        Int64\n",
       "PULocationID                      Int64\n",
       "DOLocationID                      Int64\n",
       "passenger_count                   Int64\n",
       "trip_distance                   float64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "ehail_fee                       float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "payment_type                      Int64\n",
       "trip_type                       float64\n",
       "congestion_surcharge            float64\n",
       "cbd_congestion_fee              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixed\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8a50264-11c1-40f1-bb2e-b03c375d54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sqlalchemy create_engine and give it an address to create the connection to the engine\n",
    "sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e55446f-5d9e-4d6d-9f1b-85972558d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE green_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53), \n",
      "\tcbd_congestion_fee FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the dataframe and create_engine connection to create the table, providing a name \n",
    "print(pd.io.sql.get_schema(df, name='green_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a477ed37-77d8-4cbc-a5bb-0f3cd0630077",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (91095092.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mselect count(1) from green_taxi_data\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df.head(n=0).to_sql(name='green_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff814990-0131-4f2d-b65a-b06c87722232",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Unrecognized filesystem type in URI: https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-11.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowInvalid\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m table_name = \u001b[33m\"\u001b[39m\u001b[33mgreen_taxi_data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m batch_size = \u001b[32m100_000\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m pf = \u001b[43mpq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mParquetFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparquet_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m first = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(pf.iter_batches(batch_size=batch_size), total=pf.num_row_groups):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/docker-ws-de-zoomcamp/pipeline/.venv/lib/python3.13/site-packages/pyarrow/parquet/core.py:321\u001b[39m, in \u001b[36mParquetFile.__init__\u001b[39m\u001b[34m(self, source, metadata, common_metadata, read_dictionary, binary_type, list_type, memory_map, buffer_size, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, filesystem, page_checksum_verification, arrow_extensions_enabled)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, common_metadata=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    312\u001b[39m              read_dictionary=\u001b[38;5;28;01mNone\u001b[39;00m, binary_type=\u001b[38;5;28;01mNone\u001b[39;00m, list_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    313\u001b[39m              memory_map=\u001b[38;5;28;01mFalse\u001b[39;00m, buffer_size=\u001b[32m0\u001b[39m, pre_buffer=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    316\u001b[39m              thrift_container_size_limit=\u001b[38;5;28;01mNone\u001b[39;00m, filesystem=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    317\u001b[39m              page_checksum_verification=\u001b[38;5;28;01mFalse\u001b[39;00m, arrow_extensions_enabled=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    319\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_source = \u001b[38;5;28mgetattr\u001b[39m(source, \u001b[33m'\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     filesystem, source = \u001b[43m_resolve_filesystem_and_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m filesystem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    324\u001b[39m         source = filesystem.open_input_file(source)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/docker-ws-de-zoomcamp/pipeline/.venv/lib/python3.13/site-packages/pyarrow/fs.py:183\u001b[39m, in \u001b[36m_resolve_filesystem_and_path\u001b[39m\u001b[34m(path, filesystem, memory_map)\u001b[39m\n\u001b[32m    181\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    185\u001b[39m     path = filesystem.normalize_path(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/docker-ws-de-zoomcamp/pipeline/.venv/lib/python3.13/site-packages/pyarrow/fs.py:174\u001b[39m, in \u001b[36m_resolve_filesystem_and_path\u001b[39m\u001b[34m(path, filesystem, memory_map)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists_locally:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m         filesystem, path = \u001b[43mFileSystem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    176\u001b[39m         msg = \u001b[38;5;28mstr\u001b[39m(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/docker-ws-de-zoomcamp/pipeline/.venv/lib/python3.13/site-packages/pyarrow/_fs.pyx:503\u001b[39m, in \u001b[36mpyarrow._fs.FileSystem.from_uri\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/docker-ws-de-zoomcamp/pipeline/.venv/lib/python3.13/site-packages/pyarrow/_fs.pyx:457\u001b[39m, in \u001b[36mpyarrow._fs.FileSystem._native_from_uri\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/docker-ws-de-zoomcamp/pipeline/.venv/lib/python3.13/site-packages/pyarrow/error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/docker-ws-de-zoomcamp/pipeline/.venv/lib/python3.13/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowInvalid\u001b[39m: Unrecognized filesystem type in URI: https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-11.parquet"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "engine = create_engine(\"postgresql://root:root@localhost:5432/ny_taxi\")\n",
    "\n",
    "# Enforce dtypes (nullable-safe)\n",
    "dtype_map = {\n",
    "    \"VendorID\": \"Int64\",\n",
    "    \"passenger_count\": \"Int64\",\n",
    "    \"RatecodeID\": \"Int64\",\n",
    "    \"PULocationID\": \"Int64\",\n",
    "    \"DOLocationID\": \"Int64\",\n",
    "    \"payment_type\": \"Int64\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"extra\": \"float64\",\n",
    "    \"mta_tax\": \"float64\",\n",
    "    \"tip_amount\": \"float64\",\n",
    "    \"tolls_amount\": \"float64\",\n",
    "    \"improvement_surcharge\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"congestion_surcharge\": \"float64\",\n",
    "    \"cbd_congestion_fee\": \"float64\"\n",
    "}\n",
    "\n",
    "# Green taxi typically uses lpep_* datetimes, but we'll handle either safely\n",
    "date_cols = [\n",
    "    \"lpep_pickup_datetime\",\n",
    "    \"lpep_dropoff_datetime\",\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\"\n",
    "]\n",
    "\n",
    "parquet_path = '/workspaces/docker-ws-de-zoomcamp/green_tripdata_2025-11.parquet' # adjust if needed\n",
    "table_name = \"green_taxi_data\"\n",
    "batch_size = 100_000\n",
    "\n",
    "pf = pq.ParquetFile(parquet_path)\n",
    "\n",
    "first = True\n",
    "\n",
    "for batch in tqdm(pf.iter_batches(batch_size=batch_size), total=pf.num_row_groups):\n",
    "    df = batch.to_pandas()\n",
    "\n",
    "    # Datetime coercion (only if the columns exist)\n",
    "    for c in date_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Enforce dtypes (only for columns that exist in this parquet)\n",
    "    for col, dt in dtype_map.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        if dt == \"Int64\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "        elif dt == \"float64\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"float64\")\n",
    "        elif dt == \"string\":\n",
    "            df[col] = df[col].astype(\"string\")\n",
    "\n",
    "    # Create table on first batch (schema only)\n",
    "    if first:\n",
    "        df.head(0).to_sql(name=table_name, con=engine, if_exists=\"replace\", index=False)\n",
    "        first = False\n",
    "        print(\"Table created:\", table_name)\n",
    "\n",
    "    # Append batch\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "        chunksize=10_000\n",
    "    )\n",
    "\n",
    "    print(\"Inserted:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9f8f8-e78f-4cdb-a99a-e9e9493dd454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
